# Description: This file contains the path to the models and the temperature and top_p values for the generation of the conversers.

VICUNA_13B_PATH = "/model/BJiao/vicuna-13b-v1-5/vicuna-13b-v1.5" #TODO: add path
VICUNA_7B_PATH = "/model/BJiao/vicuna-7b-v1-5/vicuna-7b-v1.5" #TODO: add path
LLAMA_2_7B_PATH = "/model/BJiao/Llama-2-7b-chat-hf/Llama-2-7b-chat-hf" #TODO: add path
LLAMA_2_13B_PATH = "/model/BJiao/Llama-2-13b-chat-hf/Llama-2-13b-chat-hf" #TODO: add path
LLAMA_3_8B_PATH = "" #TODO: add path
DEEPSEEK_PATH = "/model/BJiao/deepseek-coder-7b-instru/deepseek-coder-7b-instruct-v1.5" #TODO: add path
CODELLAMA_7B_PATH = "" #TODO: add path
CODELLAMA_13B_PATH = "/model/BJiao/CodeLlama-13b-Instr-hf/CodeLlama-13b-Instruct-hf" #TODO: add path
QWEN_7B_PATH = "/model/BJiao/Qwen1-5-7B-Chat/Qwen1.5-7B-Chat" #TODO: add path
QWEN_14B_PATH = "/model/BJiao/Qwen1-5-14B-Chat/Qwen1.5-14B-Chat" #TODO: add path
CHATGLM3_PATH = "/model/BJiao/chatglm3-6b/chatglm3-6b" #TODO: add path
BAICHUAN_7B_PATH = "/model/BJiao/Llama-2-7b-chat-hf/Baichuan2-7B-Chat"
BAICHUAN_13B_PATH = "/model/BJiao/Llama-2-7b-chat-hf/Baichuan2-13B-Chat"

PEFT_PATH = f'/home/fnii/workspace/finetune/scripts/src/output/checkpoint-200'

OUTPATH = ""

TEMP = 0
TOP_P = 0.9
TOP_K = 1